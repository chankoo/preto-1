{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9797d479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193/1075729845.py:73: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['IS_VACATION'] = df['IS_VACATION'].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "# --- 1. 사전 준비 ---\n",
    "# 다른 모듈에서 생성된 데이터프레임 및 헬퍼 데이터/함수를 임포트\n",
    "from services.tables.HR_Core.basic_info_table import emp_df\n",
    "from services.tables.HR_Core.department_table import department_df, parent_map_dept, dept_level_map, dept_name_map\n",
    "from services.tables.HR_Core.department_info_table import department_info_df\n",
    "from services.tables.Time_Attendance.working_system_table import work_sys_df\n",
    "from services.tables.Time_Attendance.working_type_table import work_type_df\n",
    "from services.tables.Time_Attendance.working_info_table import work_info_df\n",
    "from services.helpers.utils import find_parents\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "today_date_obj = datetime.datetime.now().date()\n",
    "start_date_range = date(2020, 1, 1)\n",
    "date_range_series = pd.to_datetime(pd.date_range(start=start_date_range, end=today_date_obj, freq='D'))\n",
    "today_ts = pd.to_datetime(today_date_obj)\n",
    "\n",
    "# --- 2. 헬퍼 데이터(퇴사자 그룹) 및 함수 정의 ---\n",
    "leavers_df = emp_df[emp_df['CURRENT_EMP_YN'] == 'N'].copy()\n",
    "leavers_shuffled = leavers_df.sample(frac=1, random_state=42)\n",
    "burnout_leaver_ids = set(leavers_shuffled.iloc[:int(len(leavers_shuffled) * 0.3)]['EMP_ID'])\n",
    "low_engagement_leaver_ids = set(leavers_shuffled.iloc[int(len(leavers_shuffled) * 0.3):int(len(leavers_shuffled) * 0.6)]['EMP_ID'])\n",
    "\n",
    "shift_cycles = {'4조 2교대': ['주간', '야간', '비번', '휴무'], '4조 3교대': ['주간', '주간', '오후', '오후', '휴무', '야간', '야간', '비번', '휴무'], '3조 2교대': ['주간', '야간', '비번', '휴무'], '2조 2교대': ['주간', '야간', '비번', '휴무']}\n",
    "def get_shift_type_vectorized(sys_name, days_since_hire, offset):\n",
    "    cycle = shift_cycles.get(sys_name); return cycle[(days_since_hire + offset) % len(cycle)] if cycle else ''\n",
    "\n",
    "# --- 3. 스캐폴드 생성 및 정보 통합 ---\n",
    "emp_dates_df = emp_df[['EMP_ID', 'IN_DATE', 'OUT_DATE']].copy()\n",
    "emp_ids = emp_dates_df['EMP_ID'].unique()\n",
    "scaffold_index = pd.MultiIndex.from_product([emp_ids, date_range_series], names=['EMP_ID', 'DATE'])\n",
    "df = pd.DataFrame(index=scaffold_index).reset_index()\n",
    "df = pd.merge(df, emp_dates_df, on='EMP_ID', how='left')\n",
    "df = df[(df['DATE'] >= df['IN_DATE']) & (pd.isna(df['OUT_DATE']) | (df['DATE'] <= df['OUT_DATE']))].copy()\n",
    "df = pd.merge_asof(\n",
    "    df.sort_values('DATE'),\n",
    "    work_info_df.sort_values('WORK_ASSIGN_START_DATE'),\n",
    "    left_on='DATE', right_on='WORK_ASSIGN_START_DATE', by='EMP_ID', direction='backward'\n",
    ")\n",
    "df = df.dropna(subset=['WORK_SYS_ID'])\n",
    "\n",
    "# --- 4. 근무 유형 및 부서 정보 추가 ---\n",
    "work_sys_name_map = work_sys_df.set_index('WORK_SYS_ID')['WORK_SYS_NAME'].to_dict()\n",
    "df['WORK_SYS_NAME'] = df['WORK_SYS_ID'].map(work_sys_name_map)\n",
    "is_shift_mask = df['WORK_SYS_NAME'] != '일반 근무'\n",
    "df = pd.merge_asof(df.sort_values('DATE'), department_info_df.sort_values('DEP_APP_START_DATE'), left_on='DATE', right_on='DEP_APP_START_DATE', by='EMP_ID', direction='backward')\n",
    "parent_info = df['DEP_ID'].apply(lambda x: find_parents(x, dept_level_map, parent_map_dept, dept_name_map))\n",
    "df = pd.concat([df, parent_info], axis=1)\n",
    "df['DAY_OF_WEEK'] = df['DATE'].dt.weekday; df['IS_WEEKEND'] = df['DAY_OF_WEEK'] >= 5\n",
    "df['DAYS_SINCE_HIRE'] = (df['DATE'] - df['IN_DATE']).dt.days\n",
    "shift_start_offsets_map = {emp_id: random.randint(0, 100) for emp_id in emp_ids}\n",
    "df['SHIFT_OFFSET'] = df['EMP_ID'].map(shift_start_offsets_map)\n",
    "df = df.dropna(subset=['WORK_SYS_NAME'])\n",
    "df['WORK_TYPE_NAME'] = ''\n",
    "if is_shift_mask.any():\n",
    "    df.loc[is_shift_mask, 'WORK_TYPE_NAME'] = np.vectorize(get_shift_type_vectorized)(df.loc[is_shift_mask, 'WORK_SYS_NAME'], df.loc[is_shift_mask, 'DAYS_SINCE_HIRE'], df.loc[is_shift_mask, 'SHIFT_OFFSET'])\n",
    "df.loc[~is_shift_mask, 'WORK_TYPE_NAME'] = '주간'\n",
    "\n",
    "# --- 5. 휴가 생성 및 출퇴근 시간/비고 생성 ---\n",
    "workable_day_mask = ~((df['WORK_SYS_NAME'] == '일반 근무') & df['IS_WEEKEND']) & ~df['WORK_TYPE_NAME'].isin(['비번', '휴무'])\n",
    "workable_days_df = df[workable_day_mask].copy(); workable_days_df['YEAR'] = workable_days_df['DATE'].dt.year\n",
    "sampled_dfs = [group.sample(n=min(len(group), random.randint(15, 25))) for name, group in workable_days_df.groupby(['EMP_ID', 'YEAR'])]\n",
    "if sampled_dfs:\n",
    "    vacation_df = pd.concat(sampled_dfs, ignore_index=True); vacation_df['IS_VACATION'] = True\n",
    "    df = pd.merge(df, vacation_df[['EMP_ID', 'DATE', 'IS_VACATION']], on=['EMP_ID', 'DATE'], how='left')\n",
    "df['IS_VACATION'] = df['IS_VACATION'].fillna(False).astype(bool)\n",
    "\n",
    "df['WORK_ETC'] = np.where(df['IS_VACATION'], '휴가', np.where(is_shift_mask, df['WORK_SYS_NAME'] + '(' + df['WORK_TYPE_NAME'] + ')', np.where(df['IS_WEEKEND'], '주말 휴무', '일반 근무(평일)')))\n",
    "df['DATE_START_TIME'] = '-'; df['DATE_END_TIME'] = '-'\n",
    "work_day_mask = ~df['WORK_ETC'].isin(['휴가', '주말 휴무', '비번', '휴무'])\n",
    "normal_work_mask = work_day_mask & ~is_shift_mask\n",
    "shift_work_day_mask = work_day_mask & is_shift_mask\n",
    "\n",
    "if normal_work_mask.sum() > 0:\n",
    "    df.loc[normal_work_mask, 'START_HOURS'] = np.random.randint(8, 10, size=normal_work_mask.sum())\n",
    "    df.loc[normal_work_mask, 'START_MINUTES'] = np.random.randint(0, 60, size=normal_work_mask.sum())\n",
    "    df.loc[normal_work_mask, 'WORK_DURATION_MINUTES'] = 8 * 60 + np.random.randint(0, 181, size=normal_work_mask.sum())\n",
    "    \n",
    "    rd_mask = normal_work_mask & (df['OFFICE_NAME'] == 'R&D Office')\n",
    "    if rd_mask.any(): df.loc[rd_mask, 'WORK_DURATION_MINUTES'] = 8 * 60 + np.random.randint(-60, 301, size=rd_mask.sum())\n",
    "    strategy_mask = normal_work_mask & (df['OFFICE_NAME'] == 'Strategy Office')\n",
    "    if strategy_mask.any(): df.loc[strategy_mask, 'WORK_DURATION_MINUTES'] = 8 * 60 + np.random.randint(0, 241, size=strategy_mask.sum())\n",
    "    gs_mask = normal_work_mask & (df['OFFICE_NAME'] == 'Global Sales Office')\n",
    "    if gs_mask.any(): df.loc[gs_mask, 'START_HOURS'] = np.random.randint(9, 11, size=gs_mask.sum())\n",
    "    \n",
    "    df['ONE_YEAR_BEFORE_OUT'] = df['OUT_DATE'] - pd.DateOffset(years=1)\n",
    "    burnout_mask = normal_work_mask & (df['EMP_ID'].isin(burnout_leaver_ids)) & (df['DATE'] >= df['ONE_YEAR_BEFORE_OUT'])\n",
    "    if burnout_mask.any(): df.loc[burnout_mask, 'WORK_DURATION_MINUTES'] = 8 * 60 + np.random.randint(120, 300, size=burnout_mask.sum())\n",
    "    low_engagement_mask = normal_work_mask & (df['EMP_ID'].isin(low_engagement_leaver_ids)) & (df['DATE'] >= df['ONE_YEAR_BEFORE_OUT'])\n",
    "    if low_engagement_mask.any(): df.loc[low_engagement_mask, 'WORK_DURATION_MINUTES'] = 8 * 60 + np.random.randint(0, 31, size=low_engagement_mask.sum())\n",
    "    \n",
    "    df.loc[normal_work_mask, 'DATE_START_TIME'] = [f\"{int(h):02d}:{int(m):02d}\" for h, m in zip(df.loc[normal_work_mask, 'START_HOURS'], df.loc[normal_work_mask, 'START_MINUTES'])]\n",
    "    valid_starts_mask = normal_work_mask & pd.to_datetime(df['DATE_START_TIME'], format='%H:%M', errors='coerce').notna()\n",
    "    if valid_starts_mask.any():\n",
    "        start_dt = pd.to_datetime(df.loc[valid_starts_mask, 'DATE'].astype(str) + ' ' + df.loc[valid_starts_mask, 'DATE_START_TIME'])\n",
    "        timedeltas = pd.to_timedelta(df.loc[valid_starts_mask, 'WORK_DURATION_MINUTES'], unit='m'); timedeltas.index = start_dt.index\n",
    "        end_datetimes = start_dt + timedeltas\n",
    "        df.loc[valid_starts_mask, 'DATE_END_TIME'] = end_datetimes.dt.strftime('%H:%M')\n",
    "\n",
    "if shift_work_day_mask.any():\n",
    "    shift_df = df[shift_work_day_mask].copy()\n",
    "    shift_df = pd.merge(shift_df, work_type_df, on=['WORK_SYS_ID', 'WORK_TYPE_NAME'], how='left')\n",
    "    shift_df['SCHED_START_DT'] = pd.to_datetime(shift_df['DATE'].dt.strftime('%Y-%m-%d') + ' ' + shift_df['WORK_START_TIME'], errors='coerce')\n",
    "    shift_df['SCHED_END_DT'] = pd.to_datetime(shift_df['DATE'].dt.strftime('%Y-%m-%d') + ' ' + shift_df['WORK_END_TIME'], errors='coerce')\n",
    "    overnight_mask = shift_df['SCHED_END_DT'] < shift_df['SCHED_START_DT']\n",
    "    shift_df.loc[overnight_mask, 'SCHED_END_DT'] += pd.Timedelta(days=1)\n",
    "    shift_df['SHIFT_OVERTIME'] = np.where(np.random.rand(len(shift_df)) < 0.2, np.random.randint(60, 121, size=len(shift_df)), 0)\n",
    "    prod_shift_mask = shift_df['OFFICE_NAME'] == 'Production Office'\n",
    "    if prod_shift_mask.any():\n",
    "        shift_df.loc[prod_shift_mask, 'SHIFT_OVERTIME'] = np.random.randint(60, 181, size=prod_shift_mask.sum())\n",
    "    shift_df['FINAL_END_DT'] = shift_df['SCHED_END_DT'] + pd.to_timedelta(shift_df['SHIFT_OVERTIME'], unit='m')\n",
    "    df.loc[shift_work_day_mask, 'DATE_START_TIME'] = shift_df['WORK_START_TIME']\n",
    "    df.loc[shift_work_day_mask, 'DATE_END_TIME'] = shift_df['FINAL_END_DT'].dt.strftime('%H:%M')\n",
    "\n",
    "# --- 6. 최종 DataFrame 정리 ---\n",
    "final_columns = ['EMP_ID', 'DATE', 'DATE_START_TIME', 'DATE_END_TIME', 'WORK_ETC']\n",
    "detailed_work_info_df = df[final_columns].copy()\n",
    "detailed_work_info_df_for_gsheet = detailed_work_info_df.copy()\n",
    "start_date_for_sheet = pd.to_datetime('2023-01-01')\n",
    "detailed_work_info_df_for_gsheet = detailed_work_info_df_for_gsheet[detailed_work_info_df_for_gsheet['DATE'] >= start_date_for_sheet].copy()\n",
    "detailed_work_info_df_for_gsheet['DATE'] = detailed_work_info_df_for_gsheet['DATE'].dt.strftime('%Y-%m-%d')\n",
    "for col in detailed_work_info_df_for_gsheet.columns:\n",
    "    detailed_work_info_df_for_gsheet[col] = detailed_work_info_df_for_gsheet[col].astype(str)\n",
    "detailed_work_info_df_for_gsheet = detailed_work_info_df_for_gsheet.replace({'None':'', 'NaT':'', 'nan':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f976d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
